---

# update all ubuntu nodes
- name: get update for all ubnutu hosts, then turn off swap for all
  hosts: ubuntu
  become: yes
  gather_facts: yes

  tasks:

    - name: update all ubuntu hosts
      apt:
        update_cache: yes

    - name: temporarily disable swap filw
      shell: |
        sudo swapoff -a

    - name: Disable SWAP in fstab
      replace:
        path: /etc/fstab
        regexp: '^([^#].*?\sswap\s+sw\s+.*)$'
        replace: '# \1'

    - name: test if swap is off
      shell: sudo swapon --show

# install containerd, runc, cni on kube nodes
- name: install containerd, runc, cni
  hosts: kubernetes
  become: yes
  gather_facts: no

  vars:

    - download_dest: /home/jack
      # vars for containerd-related installations
    - containerd_version: 1.6.24
    - runc_version: 1.1.9
    - cni_version: 1.3.0
      # also can verify downloaded file in the future if needed, via digital signatures, for now only test on basic sha256
    - containerd_sha256: a56fac5ba03c3d6f74ceae14abdc9fafabcba900105e9890c0ac895cc00164ad
    - cni_sha256: 754a71ed60a4bd08726c3af705a7d55ee3df03122b12e389fdba4bea35d7dd7e

  tasks:

    # install the basic components, containerd, runc, and cni-plugin
    - name: download containerd
      get_url:
        url: https://github.com/containerd/containerd/releases/download/v{{ containerd_version }}/containerd-{{ containerd_version }}-linux-amd64.tar.gz
        dest: "{{ download_dest }}"
        checksum: sha256:"{{ containerd_sha256 }}"

    - name: download containerd-service
      get_url:
        url: https://raw.githubusercontent.com/containerd/containerd/main/containerd.service
        dest: "{{ download_dest }}"

    - name: download runc
      get_url:
        url: https://github.com/opencontainers/runc/releases/download/v{{ runc_version }}/runc.amd64
        dest: "{{ download_dest }}"
    # checksum: asc: 

    - name: download cni plugin
      get_url:
        url: https://github.com/containernetworking/plugins/releases/download/v{{ cni_version }}/cni-plugins-linux-amd64-v{{ cni_version }}.tgz
        dest: "{{ download_dest }}"
        checksum: sha256:"{{ cni_sha256 }}"

    # install downlowded files
    - name: install containerd
      shell: |
        sudo chmod +x containerd-{{ containerd_version }}-linux-amd64.tar.gz
        sudo tar Cxzvf /usr/local containerd-{{ containerd_version }}-linux-amd64.tar.gz

    - name: install containerd-service
      shell: |
        sudo mv containerd.service /usr/lib/systemd/system/
        sudo systemctl daemon-reload
        sudo systemctl enable --now containerd
        sudo systemctl status containerd

    - name: install runc
      shell: |
        sudo chmod +x runc.amd64
        sudo install -m 755 runc.amd64 /usr/local/sbin/runc

    - name: set cgroup
      shell: |
        sudo mkdir -p /etc/containerd/
        containerd config default | sudo tee /etc/containerd/config.toml
        sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
        sudo systemctl restart containerd

    - name: install cni
      shell: |
        sudo chmod +x cni-plugins-linux-amd64-v{{ cni_version }}.tgz
        mkdir -p /opt/cni/bin
        sudo tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v{{ cni_version }}.tgz

    # delete downloaded files (if exist)
    - block:
        - shell: |
            [ ! -e containerd-{{ containerd_version }}-linux-amd64.tar.gz ] || rm containerd-{{ containerd_version }}-linux-amd64.tar.gz
            [ ! -e containerd-service ] || rm containerd-service
            [ ! -e runc.amd64 ] || rm runc.amd64
            [ ! -e cni-plugins-linux-amd64-v{{ cni_version }}.tgz ] || rm cni-plugins-linux-amd64-v{{ cni_version }}.tgz
      rescue:
        - debug:
            msg: 'Cannot seem to delete the files!! '
      always:
        - debug:
            msg: 'Seems like everything went through. '

# enable ipv4_forwarding on kube nodes
- name: enable ipv4 forward
  hosts: kubernetes
  become: yes
  gather_facts: no

  tasks:

    - name: enable ipv4 forward
      shell: |
        cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
        overlay
        br_netfilter
        EOF
        sudo modprobe overlay
        sudo modprobe br_netfilter  
        cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
        net.bridge.bridge-nf-call-iptables  = 1
        net.bridge.bridge-nf-call-ip6tables = 1
        net.ipv4.ip_forward                 = 1
        EOF
        sudo sysctl --system
        lsmod | grep br_netfilter && lsmod | grep overlay
        sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward

# install kubeadm, kubelet, kubectl on kube nodes
- name: install kubeadm, kubelet, kubectl
  hosts: kubernetes
  become: yes
  gather_facts: no

  tasks:

    - name: add kubernetes gpg key
      get_url:
        url: https://dl.k8s.io/apt/doc/apt-key.gpg
        dest: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: add kubernetes repo
      apt_repository:
        filename: /etc/apt/sources.list.d/kubernetes.list
        repo: 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main'

    - name: gather apt updates
      apt:
        update_cache: yes

    - name: download components
      apt: 
        pkg:
          - kubeadm
          - kubelet
          - kubectl

    - name: hold auto updates for now
      shell: |
        sudo apt-mark hold kubelet kubeadm kubectl

# update RTC since some nodes might be off
- name: update RTC
  hosts: ubuntu
  become: yes
  gather_facts: no

  tasks:
    - name: update RTC
      shell: |
        sudo systemctl unmask systemd-timesyncd
        sudo apt install systemd-timesyncd
        sudo systemctl enable systemd-timesyncd.service
        sudo systemctl start systemd-timesyncd.service

# install helm on all masters
- name: install helm on all masters
  hosts: masters
  become: yes
  gather_facts: no

  tasks:

    - name: install helm
      become: yes
      shell: |
        curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
        sudo apt-get install apt-transport-https --yes
        echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
        sudo apt-get update
        sudo apt-get install helm

# initialize cluster 1
- name: initialize cluster 1
  hosts: cluster1_master
  become: yes
  gather_facts: no

  vars:
    - home_path: /home/jack
    - username: jack

  tasks:

    - name: cluster 1 initialize
      shell: |
        sudo kubeadm init --pod-network-cidr=10.244.0.0/16 >> cluster_initialized.txt
      args:
        chdir: $HOME
        creates: cluster_initialized.txt

    - name: create .kube config
      become: yes
      shell: |
        mkdir -p $HOME/.kube
        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
        sudo chown $(id -u):$(id -g) $HOME/.kube/config

    - name: Install flannel Pod network
      shell:  |
        kubectl create ns kube-flannel
        kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged
        helm repo add flannel https://flannel-io.github.io/flannel/
        helm install flannel --set podCidr="10.244.0.0/16" --namespace kube-flannel flannel/flannel

    - name: Get join token
      become: yes
      shell: |
        sudo kubeadm token create  --print-join-command
      register: kubernetes_join_command

    - name: Copy join command to local file.
      become: yes
      local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=0777

# join cluster 1
- name: cluster1 workers join
  hosts: cluster1_worker
  become: yes
  gather_facts: no

  tasks:

    - name: Copy join command from Ansiblehost to the worker nodes.
      become: yes
      copy:
        src: /tmp/kubernetes_join_command
        dest: /tmp/kubernetes_join_command
        mode: 0777

    - name: Join the Worker nodes to the cluster.
      become: yes
      command: sh /tmp/kubernetes_join_command
      register: joined_or_not           

# initialize cluster 2
- name: initialize cluster 2
  hosts: cluster2_master
  become: yes
  gather_facts: no

  vars:
    - home_path: /home/jack
    - username: jack

  tasks:

    - name: cluster 2 initialize
      shell: |
        sudo kubeadm init --pod-network-cidr=10.244.0.0/16 >> cluster_initialized.txt
      args:
        chdir: $HOME
        creates: cluster_initialized.txt

    - name: create .kube config
      become: yes
      shell: |
        mkdir -p $HOME/.kube
        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
        sudo chown $(id -u):$(id -g) $HOME/.kube/config

    - name: Install flannel Pod network
      shell:  |
        kubectl create ns kube-flannel
        kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged
        helm repo add flannel https://flannel-io.github.io/flannel/
        helm install flannel --set podCidr="10.244.0.0/16" --namespace kube-flannel flannel/flannel

    - name: Get join token
      become: yes
      shell: |
        sudo kubeadm token create  --print-join-command
      register: kubernetes_join_command

    - name: Copy join command to local file.
      become: yes
      local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=0777

# join cluster 2
- name: cluster2 workers join
  hosts: cluster2_worker
  become: yes
  gather_facts: no

  tasks:

    - name: Copy join command from Ansiblehost to the worker nodes.
      become: yes
      copy:
        src: /tmp/kubernetes_join_command
        dest: /tmp/kubernetes_join_command
        mode: 0777

    - name: Join the Worker nodes to the cluster.
      become: yes
      command: sh /tmp/kubernetes_join_command
      register: joined_or_not 

# initialize cluster 3
- name: initialize cluster 3
  hosts: cluster3_master
  become: yes
  gather_facts: no

  vars:
    - home_path: /home/jack
    - username: jack

  tasks:

    - name: cluster 3 initialize
      shell: |
        sudo kubeadm init --pod-network-cidr=10.244.0.0/16 >> cluster_initialized.txt
      args:
        chdir: $HOME
        creates: cluster_initialized.txt

    - name: create .kube config
      become: yes
      shell: |
        mkdir -p $HOME/.kube
        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
        sudo chown $(id -u):$(id -g) $HOME/.kube/config

    - name: Install flannel Pod network
      shell:  |
        kubectl create ns kube-flannel
        kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged
        helm repo add flannel https://flannel-io.github.io/flannel/
        helm install flannel --set podCidr="10.244.0.0/16" --namespace kube-flannel flannel/flannel

    - name: Get join token
      become: yes
      shell: |
        sudo kubeadm token create  --print-join-command
      register: kubernetes_join_command

    - name: Copy join command to local file.
      become: yes
      local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=0777

# join cluster 3
- name: cluster3 workers join
  hosts: cluster3_worker
  become: yes
  gather_facts: no

  tasks:

    - name: Copy join command from Ansiblehost to the worker nodes.
      become: yes
      copy:
        src: /tmp/kubernetes_join_command
        dest: /tmp/kubernetes_join_command
        mode: 0777

    - name: Join the Worker nodes to the cluster.
      become: yes
      command: sh /tmp/kubernetes_join_command
      register: joined_or_not 

